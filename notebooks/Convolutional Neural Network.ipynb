{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import csv\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "resize_x = 80\n",
    "resize_y = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(\n",
    "        x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(\n",
    "        x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/convolutional/data.csv', 'rb') as mycsvfile:\n",
    "    thedata = csv.reader(mycsvfile, delimiter=':')\n",
    "    thedata.next()\n",
    "    for row in thedata:\n",
    "        images.append(np.fromstring(row[0].replace(\"[\", \"\").replace(\"]\", \"\"), dtype=int, sep=\" \"))\n",
    "        labels.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_labels = pd.get_dummies(labels)\n",
    "labels = np.array(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = np.array(images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images, labels = shuffle(images, labels, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = images[:350]\n",
    "Y_train = labels.reshape(len(labels), -1)[:350]\n",
    "\n",
    "X_test = images[350:]\n",
    "Y_test = labels.reshape(len(labels), -1)[350:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input and output variables\n",
    "\n",
    "INPUTS = resize_x * resize_y * 3\n",
    "OUTPUTS = 2\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 51\n",
    "LEARNING_RATE = 1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Interactive session because of notebook environment\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Input and output placeholder\n",
    "x = tf.placeholder(tf.float32, [None, INPUTS])\n",
    "y = tf.placeholder(tf.float32, [None, OUTPUTS])\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# First Convolutional Layer\n",
    "x_image = tf.reshape(x, [-1, resize_x, resize_y, 3])\n",
    "W_conv_1 = tf.Variable(tf.truncated_normal([2, 2, 3, 8], stddev=0.1))\n",
    "b_conv_1 = tf.Variable(tf.constant(0.0, shape=[8]))\n",
    "h_conv_1 = tf.nn.relu(conv2d(x_image, W_conv_1) + b_conv_1)\n",
    "h_pool_1 = max_pool_2x2(h_conv_1)\n",
    "\n",
    "# Second Convolutional Layer\n",
    "W_conv_2 = tf.Variable(tf.truncated_normal([2, 2, 8, 32], stddev=0.1))\n",
    "b_conv_2 = tf.Variable(tf.constant(0.0, shape=[32]))\n",
    "h_conv_2 = tf.nn.relu(conv2d(h_pool_1, W_conv_2) + b_conv_2)\n",
    "h_pool_2 = max_pool_2x2(h_conv_2)\n",
    "\n",
    "# Third Convolutional Layer\n",
    "W_conv_3 = tf.Variable(tf.truncated_normal([2, 2, 32, 128], stddev=0.1))\n",
    "b_conv_3 = tf.Variable(tf.constant(0.0, shape=[128]))\n",
    "h_conv_3 = tf.nn.relu(conv2d(h_pool_2, W_conv_3) + b_conv_3)\n",
    "h_pool_3 = max_pool_2x2(h_conv_3)\n",
    "\n",
    "# Fourth Convolutional Layer\n",
    "W_conv_4 = tf.Variable(tf.truncated_normal([2, 2, 128, 256], stddev=0.1))\n",
    "b_conv_4 = tf.Variable(tf.constant(0.0, shape=[256]))\n",
    "h_conv_4 = tf.nn.relu(conv2d(h_pool_3, W_conv_4) + b_conv_4)\n",
    "h_pool_4 = max_pool_2x2(h_conv_4)\n",
    "\n",
    "# Densely connected layer\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([5 * 5 * 256, 1024], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.0, shape=[1024]))\n",
    "h_poolfc1_flat = tf.reshape(h_pool_4, [-1, 5 * 5 * 256])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_poolfc1_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Densely connected layer\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024, 512], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.0, shape=[512]))\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "# Dropout\n",
    "h_drop = tf.nn.dropout(h_fc2, pkeep)\n",
    "\n",
    "# Read out Layer\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([512, OUTPUTS], stddev=0.1))\n",
    "b_fc3 = tf.Variable(tf.constant(0.0, shape=[OUTPUTS]))\n",
    "y_logits = tf.matmul(h_drop, W_fc3) + b_fc3\n",
    "y_softmax = tf.nn.softmax(y_logits)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_logits, y))\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_softmax, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000, loss train 0.68673819, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0001, loss train 0.68862045, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0002, loss train 0.66413909, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0003, loss train 0.67351913, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0004, loss train 0.63135666, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0005, loss train 0.65455252, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0006, loss train 0.66915923, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0007, loss train 0.69014025, train accuracy 0.62000000, test accuracy 0.61702126\n",
      "Epoch 0008, loss train 0.66345185, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0009, loss train 0.65994585, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0010, loss train 0.62559366, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0011, loss train 0.63222533, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0012, loss train 0.66424853, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0013, loss train 0.64421445, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0014, loss train 0.66831535, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0015, loss train 0.64710981, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0016, loss train 0.64762068, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0017, loss train 0.67238462, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0018, loss train 0.61518115, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0019, loss train 0.62941962, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0020, loss train 0.71802324, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0021, loss train 0.64581406, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0022, loss train 0.67482758, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0023, loss train 0.66447031, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0024, loss train 0.67102599, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0025, loss train 0.65319878, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0026, loss train 0.65215838, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0027, loss train 0.60888761, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0028, loss train 0.66546881, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0029, loss train 0.65709680, train accuracy 0.62285715, test accuracy 0.61702126\n",
      "Epoch 0030, loss train 0.68772906, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0031, loss train 0.62675303, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0032, loss train 0.68158883, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0033, loss train 0.66731811, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0034, loss train 0.63609105, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0035, loss train 0.69223738, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0036, loss train 0.64732957, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0037, loss train 0.63893622, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0038, loss train 0.63114369, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0039, loss train 0.67455554, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0040, loss train 0.65399778, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0041, loss train 0.62298095, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0042, loss train 0.68415123, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0043, loss train 0.67174500, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0044, loss train 0.64583802, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0045, loss train 0.65630907, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0046, loss train 0.64448076, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0047, loss train 0.62515205, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0048, loss train 0.67721450, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0049, loss train 0.66142684, train accuracy 0.62285715, test accuracy 0.61590147\n",
      "Epoch 0050, loss train 0.65038866, train accuracy 0.62285715, test accuracy 0.61590147\n"
     ]
    }
   ],
   "source": [
    "loss_train_array = []\n",
    "test_accuracy_array = []\n",
    "train_accuracy_array = []\n",
    "\n",
    "for current_epoch in range(NUM_EPOCHS):\n",
    "    shuffled_index = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(shuffled_index)\n",
    "\n",
    "    train_dataset = X_train[shuffled_index]\n",
    "    train_labels = Y_train[shuffled_index]\n",
    "\n",
    "    for step in xrange(int(X_train.shape[0] / BATCH_SIZE)):\n",
    "        \n",
    "        offset = step * BATCH_SIZE\n",
    "        batch_data = train_dataset[offset:(offset + BATCH_SIZE)]\n",
    "        batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "        \n",
    "        # This dictionary maps the batch data (as a numpy array) to the\n",
    "        # node in the graph is should be fed to.\n",
    "        feed_dict = {x: batch_data, y: batch_labels, pkeep: 0.8}\n",
    "        _, loss_train = sess.run([train_step, loss],\n",
    "                                 feed_dict=feed_dict)\n",
    "\n",
    "    # We calculate the accuracies to plot their values later\n",
    "    loss_train_array.append(loss_train)\n",
    "    \n",
    "    train_accuracy = sess.run(\n",
    "        accuracy, feed_dict={x: X_train, y: Y_train, pkeep: 1.0})\n",
    "    \n",
    "    train_accuracy_array.append(train_accuracy)\n",
    "    \n",
    "    test_accuracy = sess.run(\n",
    "        accuracy, feed_dict={x: X_test, y: Y_test, pkeep: 1.0})\n",
    "    \n",
    "    test_accuracy_array.append(test_accuracy)\n",
    "\n",
    "    print (\n",
    "        'Epoch %04d, '\n",
    "        'loss train %.8f, train accuracy %.8f, test accuracy %.8f'\n",
    "        %\n",
    "        (current_epoch,\n",
    "         loss_train,\n",
    "         train_accuracy,\n",
    "         test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: /tmp/model_conv.ckpt\n"
     ]
    }
   ],
   "source": [
    "#Save model\n",
    "save_path = saver.save(sess, \"/tmp/model_conv.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "[[ 0.6078167   0.3921833 ]\n",
      " [ 0.6078167   0.3921833 ]\n",
      " [ 0.6078167   0.3921833 ]\n",
      " ..., \n",
      " [ 0.6078167   0.3921833 ]\n",
      " [ 0.6078167   0.3921833 ]\n",
      " [ 0.6078167   0.39218327]]\n"
     ]
    }
   ],
   "source": [
    "# Comparing values\n",
    "print Y_test\n",
    "\n",
    "classification = sess.run(y_softmax, feed_dict={x: X_test, pkeep: 1.0})\n",
    "print classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
