{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import dlib\n",
    "import glob\n",
    "import csv\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "resize_x = 80\n",
    "resize_y = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(\n",
    "        x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(\n",
    "        x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/convolutional/data.csv', 'rb') as mycsvfile:\n",
    "    thedata = csv.reader(mycsvfile, delimiter=':')\n",
    "    thedata.next()\n",
    "    for row in thedata:\n",
    "        images.append(np.fromstring(row[0].replace(\"[\", \"\").replace(\"]\", \"\"), dtype=int, sep=\" \"))\n",
    "        labels.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_labels = pd.get_dummies(labels)\n",
    "labels = np.array(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = np.array(images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = images[:400]\n",
    "Y_train = labels.reshape(len(labels), -1)[:400]\n",
    "\n",
    "X_test = images[20:]\n",
    "Y_test = labels.reshape(len(labels), -1)[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input and output variables\n",
    "\n",
    "INPUTS = resize_x * resize_y * 3\n",
    "OUTPUTS = 2\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 51\n",
    "LEARNING_RATE = 1e-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f95afe59050>> ignored\n"
     ]
    }
   ],
   "source": [
    "# Interactive session because of notebook environment\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Input and output placeholder\n",
    "x = tf.placeholder(tf.float32, [None, INPUTS])\n",
    "y = tf.placeholder(tf.float32, [None, OUTPUTS])\n",
    "\n",
    "# First Convolutional Layer\n",
    "# Input and output placeholder\n",
    "x = tf.placeholder(tf.float32, [None, INPUTS])\n",
    "y = tf.placeholder(tf.float32, [None, OUTPUTS])\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# First Convolutional Layer\n",
    "x_image = tf.reshape(x, [-1, resize_x, resize_y, 3])\n",
    "W_conv_1 = tf.Variable(tf.truncated_normal([2, 2, 3, 8], stddev=0.1))\n",
    "b_conv_1 = tf.Variable(tf.constant(0.0, shape=[8]))\n",
    "h_conv_1 = tf.nn.relu(conv2d(x_image, W_conv_1) + b_conv_1)\n",
    "h_pool_1 = max_pool_2x2(h_conv_1)\n",
    "\n",
    "# Second Convolutional Layer\n",
    "W_conv_2 = tf.Variable(tf.truncated_normal([2, 2, 8, 32], stddev=0.1))\n",
    "b_conv_2 = tf.Variable(tf.constant(0.0, shape=[32]))\n",
    "h_conv_2 = tf.nn.relu(conv2d(h_pool_1, W_conv_2) + b_conv_2)\n",
    "h_pool_2 = max_pool_2x2(h_conv_2)\n",
    "\n",
    "# Third Convolutional Layer\n",
    "W_conv_3 = tf.Variable(tf.truncated_normal([2, 2, 32, 128], stddev=0.1))\n",
    "b_conv_3 = tf.Variable(tf.constant(0.0, shape=[128]))\n",
    "h_conv_3 = tf.nn.relu(conv2d(h_pool_2, W_conv_3) + b_conv_3)\n",
    "h_pool_3 = max_pool_2x2(h_conv_3)\n",
    "\n",
    "# Fourth Convolutional Layer\n",
    "W_conv_4 = tf.Variable(tf.truncated_normal([2, 2, 128, 256], stddev=0.1))\n",
    "b_conv_4 = tf.Variable(tf.constant(0.0, shape=[256]))\n",
    "h_conv_4 = tf.nn.relu(conv2d(h_pool_3, W_conv_4) + b_conv_4)\n",
    "h_pool_4 = max_pool_2x2(h_conv_4)\n",
    "\n",
    "# Densely connected layer\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([5 * 5 * 256, 1024], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.0, shape=[1024]))\n",
    "h_poolfc1_flat = tf.reshape(h_pool_4, [-1, 5 * 5 * 256])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_poolfc1_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Densely connected layer\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024, 512], stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.0, shape=[512]))\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "# Dropout\n",
    "h_drop = tf.nn.dropout(h_fc2, pkeep)\n",
    "\n",
    "# Read out Layer\n",
    "W_fc3 = tf.Variable(tf.truncated_normal([512, OUTPUTS], stddev=0.1))\n",
    "b_fc3 = tf.Variable(tf.constant(0.0, shape=[OUTPUTS]))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(tf.matmul(h_drop, W_fc3) + b_fc3, y))\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(tf.matmul(h_drop, W_fc3) + b_fc3, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000, loss train 0.01551567, train accuracy 0.99250001, test accuracy 0.99255586\n",
      "Epoch 0001, loss train 0.01542919, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0002, loss train 0.00386496, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0003, loss train 0.00334567, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0004, loss train 0.00110674, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0005, loss train 0.00354418, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0006, loss train 0.00051712, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0007, loss train 0.00133888, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0008, loss train 0.00025599, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0009, loss train 0.00007332, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0010, loss train 0.00012525, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0011, loss train 0.00033774, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0012, loss train 0.00006036, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0013, loss train 0.00015519, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0014, loss train 0.00009610, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0015, loss train 0.00002055, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0016, loss train 0.00003571, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0017, loss train 0.00003144, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0018, loss train 0.00008120, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0019, loss train 0.00023234, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0020, loss train 0.00001703, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0021, loss train 0.00002993, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0022, loss train 0.00001703, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0023, loss train 0.00001892, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0024, loss train 0.00003533, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0025, loss train 0.00004498, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0026, loss train 0.00003806, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0027, loss train 0.00000943, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0028, loss train 0.00002596, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0029, loss train 0.00002312, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0030, loss train 0.00000676, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0031, loss train 0.00000486, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0032, loss train 0.00000580, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0033, loss train 0.00000412, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0034, loss train 0.00000833, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0035, loss train 0.00000421, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0036, loss train 0.00001125, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0037, loss train 0.00004945, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0038, loss train 0.00004913, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0039, loss train 0.00000270, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0040, loss train 0.00002105, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0041, loss train 0.00000708, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0042, loss train 0.00001935, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0043, loss train 0.00001116, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0044, loss train 0.00000336, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0045, loss train 0.00000280, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0046, loss train 0.00000681, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0047, loss train 0.00001951, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0048, loss train 0.00000216, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0049, loss train 0.00000603, train accuracy 1.00000000, test accuracy 1.00000000\n",
      "Epoch 0050, loss train 0.00001436, train accuracy 1.00000000, test accuracy 1.00000000\n"
     ]
    }
   ],
   "source": [
    "loss_train_array = []\n",
    "test_accuracy_array = []\n",
    "train_accuracy_array = []\n",
    "\n",
    "for current_epoch in range(NUM_EPOCHS):\n",
    "    shuffled_index = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(shuffled_index)\n",
    "\n",
    "    train_dataset = X_train[shuffled_index]\n",
    "    train_labels = Y_train[shuffled_index]\n",
    "\n",
    "    for step in xrange(int(X_train.shape[0] / BATCH_SIZE)):\n",
    "        \n",
    "        offset = step * BATCH_SIZE\n",
    "        batch_data = train_dataset[offset:(offset + BATCH_SIZE)]\n",
    "        batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "        \n",
    "        # This dictionary maps the batch data (as a numpy array) to the\n",
    "        # node in the graph is should be fed to.\n",
    "        feed_dict = {x: batch_data, y: batch_labels, pkeep: 0.8}\n",
    "        _, loss_train = sess.run([train_step, loss],\n",
    "                                 feed_dict=feed_dict)\n",
    "\n",
    "    # We calculate the accuracies to plot their values later\n",
    "    loss_train_array.append(loss_train)\n",
    "    \n",
    "    train_accuracy = sess.run(\n",
    "        accuracy, feed_dict={x: X_train, y: Y_train, pkeep: 1.0})\n",
    "    \n",
    "    train_accuracy_array.append(train_accuracy)\n",
    "    \n",
    "    test_accuracy = sess.run(\n",
    "        accuracy, feed_dict={x: X_test, y: Y_test, pkeep: 1.0})\n",
    "    \n",
    "    test_accuracy_array.append(test_accuracy)\n",
    "\n",
    "    print (\n",
    "        'Epoch %04d, '\n",
    "        'loss train %.8f, train accuracy %.8f, test accuracy %.8f'\n",
    "        %\n",
    "        (current_epoch,\n",
    "         loss_train,\n",
    "         train_accuracy,\n",
    "         test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.553792  ,  -5.43515158],\n",
       "       [  8.54269218,  -7.19680262],\n",
       "       [  6.24348688,  -6.14228439],\n",
       "       [  7.8774662 ,  -6.42351675],\n",
       "       [  6.56518793,  -6.39955282],\n",
       "       [  8.07974148,  -6.77744246],\n",
       "       [  7.61159945,  -5.78816175],\n",
       "       [  7.2906909 ,  -5.00560427],\n",
       "       [  6.31061077,  -6.76134014],\n",
       "       [  8.91503525,  -5.64068174],\n",
       "       [  6.99686384,  -5.09020233],\n",
       "       [  6.76495981,  -4.63457489],\n",
       "       [  8.04547882,  -5.44517422],\n",
       "       [  6.4825387 ,  -5.06725168],\n",
       "       [  8.5867033 ,  -4.27741289],\n",
       "       [  7.28539801,  -7.01778793],\n",
       "       [  7.26175737,  -6.5471487 ],\n",
       "       [  7.63127279,  -5.67450094],\n",
       "       [  7.20974684,  -5.19469309],\n",
       "       [  8.18650723,  -6.55686235],\n",
       "       [  7.12688684,  -6.44904947],\n",
       "       [  8.11149788,  -5.30140972],\n",
       "       [  8.47350216,  -6.46562052],\n",
       "       [  8.41492367,  -5.72136354],\n",
       "       [  8.01280785,  -6.25949907],\n",
       "       [  7.33635187,  -6.71458197],\n",
       "       [  6.49941015,  -6.73085833],\n",
       "       [  7.6509161 ,  -6.04489803],\n",
       "       [  7.1632452 ,  -6.20438528],\n",
       "       [  7.54025793,  -7.23903227],\n",
       "       [  9.5727253 ,  -6.62316847],\n",
       "       [  7.08713245,  -5.34825945],\n",
       "       [  8.04666805,  -5.19890642],\n",
       "       [  6.86164141,  -4.59243393],\n",
       "       [  7.95364046,  -5.45467043],\n",
       "       [  7.11820555,  -6.10239553],\n",
       "       [  7.1394763 ,  -5.24366331],\n",
       "       [  7.08162642,  -6.43382931],\n",
       "       [  7.50850821,  -3.77672672],\n",
       "       [  8.2152462 ,  -7.95503235],\n",
       "       [  7.65898371,  -7.24250174],\n",
       "       [  7.28172588,  -6.8791914 ],\n",
       "       [  6.42353773,  -5.91815567],\n",
       "       [  8.04358959,  -6.44925451],\n",
       "       [  8.01455307,  -6.23293161],\n",
       "       [  7.66271877,  -6.09384108],\n",
       "       [  8.55399704,  -6.937222  ],\n",
       "       [  7.46862411,  -4.48165894],\n",
       "       [  6.83227587,  -5.62485409],\n",
       "       [  8.28782654,  -6.35495234],\n",
       "       [  7.39727163,  -5.594625  ],\n",
       "       [  7.50498104,  -6.36507273],\n",
       "       [  7.53313637,  -3.23642373],\n",
       "       [  8.45584869,  -5.43200731],\n",
       "       [  7.40221977,  -5.8083415 ],\n",
       "       [  8.39376926,  -6.47824717],\n",
       "       [  7.34651995,  -6.57981682],\n",
       "       [  7.43805742,  -4.76147127],\n",
       "       [  7.65168905,  -6.37699747],\n",
       "       [  7.68429136,  -5.49202299],\n",
       "       [  7.63328409,  -5.75929451],\n",
       "       [  8.68784428,  -6.62780046],\n",
       "       [  7.99545097,  -5.51275349],\n",
       "       [  8.16752911,  -6.2132287 ],\n",
       "       [  7.39507151,  -5.80973053],\n",
       "       [  6.74130297,  -6.61227751],\n",
       "       [  8.23219681,  -6.33434629],\n",
       "       [  7.04808855,  -5.26178503],\n",
       "       [  6.77721453,  -7.24252272],\n",
       "       [  7.1177702 ,  -6.65732718],\n",
       "       [  7.60957098,  -6.39128828],\n",
       "       [  8.51189995,  -5.61818552],\n",
       "       [  9.41762161,  -5.6764493 ],\n",
       "       [  7.03128338,  -6.37480259],\n",
       "       [  8.28277779,  -7.10185528],\n",
       "       [  7.30918646,  -6.51573324],\n",
       "       [  7.23998213,  -4.57582998],\n",
       "       [  7.11149931,  -6.62189341],\n",
       "       [  7.4989295 ,  -6.19305849],\n",
       "       [  8.03152084,  -5.95944405],\n",
       "       [  6.11177778,  -4.16570854],\n",
       "       [  8.58143711,  -6.03982401],\n",
       "       [  8.58902073,  -6.4193759 ],\n",
       "       [  6.31725931,  -5.54607725],\n",
       "       [  7.77480125,  -6.5397315 ],\n",
       "       [  7.41362429,  -6.36880589],\n",
       "       [  6.69385958,  -4.34503317],\n",
       "       [  7.68937206,  -7.03930902],\n",
       "       [  9.31727409,  -7.17175388],\n",
       "       [  7.90498686,  -6.69716024],\n",
       "       [  5.76059866,  -4.49511719],\n",
       "       [  7.60464048,  -4.80895472],\n",
       "       [  7.02181387,  -5.66249418],\n",
       "       [  7.19371891,  -5.71140814],\n",
       "       [  7.22595596,  -6.12263536],\n",
       "       [  8.298563  ,  -6.78786278],\n",
       "       [  7.13520861,  -6.7511363 ],\n",
       "       [  8.3639946 ,  -6.83504677],\n",
       "       [  7.45865917,  -6.13941479],\n",
       "       [  6.43656206,  -5.5443778 ],\n",
       "       [  7.44670582,  -7.51271963],\n",
       "       [  8.88328838,  -5.72092962],\n",
       "       [  6.69416523,  -6.53973913],\n",
       "       [  8.36748219,  -7.08403444],\n",
       "       [  8.73745632,  -5.81922102],\n",
       "       [  8.71198273,  -7.11917782],\n",
       "       [  7.12354708,  -5.02252817],\n",
       "       [  7.26554346,  -6.42839289],\n",
       "       [  5.89439821,  -3.63839078],\n",
       "       [  7.77508736,  -6.78853703],\n",
       "       [  7.38131905,  -6.54116297],\n",
       "       [  6.65671873,  -4.99595022],\n",
       "       [  8.35282516,  -7.1922493 ],\n",
       "       [  8.32568169,  -5.59333563],\n",
       "       [  6.7192111 ,  -6.00676394],\n",
       "       [  8.28770256,  -6.70740557],\n",
       "       [  7.8213172 ,  -6.65048027],\n",
       "       [  6.3587904 ,  -4.82205248],\n",
       "       [  6.13583136,  -6.391078  ],\n",
       "       [  7.70537376,  -6.23585558],\n",
       "       [  6.79668903,  -5.66051245],\n",
       "       [  8.00629044,  -5.58577013],\n",
       "       [  7.94303608,  -6.4675622 ],\n",
       "       [  7.74986458,  -5.58339357],\n",
       "       [  7.73012066,  -6.12480831],\n",
       "       [  7.56350994,  -6.49677896],\n",
       "       [  7.15727234,  -5.88548231],\n",
       "       [  8.80426788,  -5.06949806],\n",
       "       [  6.71565771,  -5.82119226],\n",
       "       [  7.40834951,  -4.95291662],\n",
       "       [  6.73714018,  -6.43438721],\n",
       "       [  6.94820833,  -6.0584445 ],\n",
       "       [  8.08078098,  -6.73794031],\n",
       "       [  7.50714779,  -5.42934561],\n",
       "       [  6.71660519,  -6.64267921],\n",
       "       [  7.92095709,  -6.22853899],\n",
       "       [  7.53919268,  -5.04069471],\n",
       "       [  6.92263556,  -6.9055562 ],\n",
       "       [  7.72767782,  -4.85624599],\n",
       "       [  5.41699648,  -4.66918707],\n",
       "       [  7.53105974,  -4.94256735],\n",
       "       [  7.11142397,  -6.17902803],\n",
       "       [  6.77370024,  -5.33116198],\n",
       "       [  7.18493271,  -5.36462307],\n",
       "       [  6.71148682,  -4.96351099],\n",
       "       [  6.58203363,  -5.44275951],\n",
       "       [  8.34319115,  -5.68722677],\n",
       "       [  8.06577969,  -6.75200987],\n",
       "       [  7.0165596 ,  -5.70607853],\n",
       "       [  7.70482206,  -5.08453608],\n",
       "       [  8.53679276,  -5.90315485],\n",
       "       [  6.40703344,  -6.70893526],\n",
       "       [  8.93548775,  -5.82647181],\n",
       "       [  7.87969923,  -6.68309641],\n",
       "       [  6.74113369,  -6.12846994],\n",
       "       [  8.21647263,  -7.29966497],\n",
       "       [  6.84387589,  -5.88794804],\n",
       "       [  7.18313694,  -7.06022501],\n",
       "       [  7.53988218,  -5.3474431 ],\n",
       "       [  8.08144665,  -5.12813902],\n",
       "       [  7.92372561,  -6.53201914],\n",
       "       [  7.63531876,  -6.68920088],\n",
       "       [  7.81182146,  -4.58055925],\n",
       "       [  8.21461678,  -6.04427624],\n",
       "       [  8.56885338,  -6.12248182],\n",
       "       [  7.69156456,  -5.86979389],\n",
       "       [  6.66812038,  -6.00886393],\n",
       "       [  7.05915594,  -5.15089893],\n",
       "       [  7.14314222,  -6.28898573],\n",
       "       [  6.91208124,  -5.6007905 ],\n",
       "       [  7.62317801,  -6.51683187],\n",
       "       [  6.26020575,  -5.77599192],\n",
       "       [  6.04539156,  -5.47836018],\n",
       "       [  5.92549419,  -5.14318705],\n",
       "       [  7.80364752,  -5.6294198 ],\n",
       "       [  6.49817228,  -5.09260511],\n",
       "       [  7.27993536,  -5.35965395],\n",
       "       [  7.29143476,  -5.06241846],\n",
       "       [  7.14355612,  -6.29868841],\n",
       "       [  5.7890048 ,  -6.58012247],\n",
       "       [  7.51762962,  -7.70911217],\n",
       "       [  7.82088804,  -7.12112427],\n",
       "       [  6.22561121,  -6.27948189],\n",
       "       [  7.26260805,  -6.55183363],\n",
       "       [  7.69672251,  -6.63635206],\n",
       "       [ -6.68973398,   8.23351955],\n",
       "       [ -6.6580615 ,   8.43650055],\n",
       "       [ -6.28294039,   8.44829369],\n",
       "       [ -7.6372118 ,   8.85989952],\n",
       "       [ -7.61947632,   8.68339062],\n",
       "       [ -7.67828369,   8.00565338],\n",
       "       [ -8.36198235,  11.08818054],\n",
       "       [ -7.12545347,   8.08184242],\n",
       "       [ -7.06094599,   7.78492641],\n",
       "       [ -7.00375223,   9.06560993],\n",
       "       [ -8.08099365,   7.96906424],\n",
       "       [ -7.97742128,   8.34560394],\n",
       "       [ -7.36629963,   8.32809544],\n",
       "       [ -6.10623264,   9.01918221],\n",
       "       [ -7.08585405,   6.81130266],\n",
       "       [ -7.82791376,   8.60108089],\n",
       "       [ -7.74741125,   9.00865269],\n",
       "       [ -7.61220789,   8.73778439],\n",
       "       [ -7.97862768,   8.32688141],\n",
       "       [ -7.00763845,   8.13038445],\n",
       "       [ -7.49938726,   7.36499166],\n",
       "       [ -4.11110163,   4.64114428],\n",
       "       [ -7.55405807,   9.09656906],\n",
       "       [ -8.01276398,   7.5570159 ],\n",
       "       [ -7.56614065,   8.18088055],\n",
       "       [ -6.42695284,   7.78739882],\n",
       "       [ -6.63531637,   7.34625673],\n",
       "       [ -4.0186553 ,   4.0941534 ],\n",
       "       [ -6.69132423,   7.41199493],\n",
       "       [ -5.19626951,   7.80243397],\n",
       "       [ -6.14939451,   6.70366812],\n",
       "       [ -7.01049376,   8.12587452],\n",
       "       [ -7.03639174,   6.57657528],\n",
       "       [ -6.98495483,   8.06440163],\n",
       "       [ -6.29083109,   8.21213722],\n",
       "       [ -6.93945599,   9.00077534],\n",
       "       [ -4.91141939,   4.85220623],\n",
       "       [ -6.6140008 ,   6.46874571],\n",
       "       [ -7.20578241,   7.45363903],\n",
       "       [ -7.85761738,   8.63869858],\n",
       "       [ -4.62697124,   5.85877752],\n",
       "       [ -7.23020029,   7.85919714],\n",
       "       [ -6.58622599,   7.86452198],\n",
       "       [ -7.61647844,   7.00354862],\n",
       "       [ -8.14892769,   9.26339817],\n",
       "       [ -6.96772003,   8.58035469],\n",
       "       [ -4.77411127,   7.5285964 ],\n",
       "       [ -6.43334627,   8.106534  ],\n",
       "       [ -7.88449764,   7.90514421],\n",
       "       [ -7.42357874,   7.95271826],\n",
       "       [ -5.87047291,   7.6079092 ],\n",
       "       [ -6.14720345,   7.53832197],\n",
       "       [ -9.16995144,   9.16200066],\n",
       "       [ -3.28587699,  10.06758118],\n",
       "       [ -4.38573122,   4.74204588],\n",
       "       [ -7.02900743,   8.05561066],\n",
       "       [ -6.36195755,   8.25307465],\n",
       "       [ -6.4735136 ,   6.79185009],\n",
       "       [ -7.4751668 ,   7.9028635 ],\n",
       "       [ -7.49365854,   6.85895538],\n",
       "       [ -5.80468559,   7.32516146],\n",
       "       [ -8.35582542,   7.71112013],\n",
       "       [ -7.91201353,   8.30181122],\n",
       "       [ -6.9920826 ,   8.41121483],\n",
       "       [ -7.78129101,   8.59370613],\n",
       "       [ -8.0776329 ,   8.98439312],\n",
       "       [ -6.86855602,   7.38871956],\n",
       "       [ -7.63726616,   7.73215532],\n",
       "       [ -7.61461782,   8.75574303],\n",
       "       [ -7.47281694,   7.87976837],\n",
       "       [ -6.56086445,   7.87821579],\n",
       "       [ -6.94139528,   7.77713251],\n",
       "       [ -9.57486725,  10.78548241],\n",
       "       [ -7.61545181,   8.00625801],\n",
       "       [ -6.32183647,   7.64121962],\n",
       "       [ -7.37209463,   8.86588478],\n",
       "       [ -8.16384697,   8.41783524],\n",
       "       [ -7.27306795,   8.85365677],\n",
       "       [ -7.13997507,   7.6122303 ],\n",
       "       [ -4.2324214 ,   4.41593409],\n",
       "       [ -6.33164454,   8.14947128],\n",
       "       [ -6.32220745,   7.68931246],\n",
       "       [ -7.4592948 ,   9.14054108],\n",
       "       [ -7.83015394,   8.08522606],\n",
       "       [ -9.90662289,  10.75001144],\n",
       "       [ -6.44704199,   8.00612545],\n",
       "       [ -7.48282623,   7.49177456],\n",
       "       [ -7.97411013,   7.7742734 ],\n",
       "       [ -7.50998211,   8.80677032],\n",
       "       [ -5.204988  ,   6.07322741],\n",
       "       [ -6.93844318,   8.18347454],\n",
       "       [ -8.13093948,   7.35842466],\n",
       "       [ -7.21064234,   8.83166409],\n",
       "       [ -7.2913599 ,   8.82001686],\n",
       "       [ -7.8261776 ,   8.41160297],\n",
       "       [ -6.29898596,   7.53036928],\n",
       "       [ -8.29758072,   8.45893478],\n",
       "       [ -7.29838276,   8.06708717],\n",
       "       [ -8.08140182,   8.30886269],\n",
       "       [ -6.95466614,   7.64370298],\n",
       "       [ -6.05893469,   7.88328934],\n",
       "       [ -5.81510592,   6.32219982],\n",
       "       [ -6.05318642,   5.95387316],\n",
       "       [ -4.78924561,   5.71358871],\n",
       "       [ -6.754601  ,   6.9583497 ],\n",
       "       [ -7.02152729,   8.46504879],\n",
       "       [ -8.35303974,   8.70191574],\n",
       "       [ -6.50756693,   7.14099741],\n",
       "       [ -8.82454109,  11.18124008],\n",
       "       [ -7.30474377,   8.79680634],\n",
       "       [ -6.78533602,   7.77900219],\n",
       "       [ -7.22540712,   9.15103626],\n",
       "       [ -8.24069881,   8.45193005],\n",
       "       [ -6.20404053,   8.37920856],\n",
       "       [ -7.19232893,   8.37035561],\n",
       "       [ -7.72113991,   8.45663071],\n",
       "       [ -7.99757957,   7.51180506],\n",
       "       [ -6.76175785,   7.18884277],\n",
       "       [ -4.70591402,   8.39192963],\n",
       "       [ -7.69158316,   8.65943241],\n",
       "       [ -8.71403885,  10.09635162],\n",
       "       [ -8.3488903 ,   7.5287571 ],\n",
       "       [ -6.14913511,   7.07477808],\n",
       "       [ -7.10697842,   7.69629478],\n",
       "       [ -8.29313183,   8.28844166],\n",
       "       [ -8.23766518,   8.03586864],\n",
       "       [ -7.76252413,   6.86722565],\n",
       "       [ -6.4011116 ,   8.50938988],\n",
       "       [ -6.81888819,   7.84057188],\n",
       "       [ -7.88904953,   8.13613319],\n",
       "       [ -7.27565241,   8.09940529],\n",
       "       [ -8.15231991,   7.90399551],\n",
       "       [ -8.26996136,   8.19579124],\n",
       "       [ -6.94207335,   8.26194572],\n",
       "       [ -6.8893013 ,   7.54621029],\n",
       "       [ -6.87935543,   7.70044947],\n",
       "       [ -6.62781   ,   8.61717415],\n",
       "       [ -6.97201157,   8.45441055],\n",
       "       [ -7.41721201,   8.51391888],\n",
       "       [ -7.08180571,   8.70378304],\n",
       "       [ -7.75416183,   9.27628231],\n",
       "       [ -8.33122826,   8.55061436],\n",
       "       [ -7.18601847,   8.06749153],\n",
       "       [ -6.12749338,   7.52500772],\n",
       "       [ -6.68935394,   8.04144859],\n",
       "       [ -5.68327045,   7.43819046],\n",
       "       [ -7.50195694,   7.94562531],\n",
       "       [ -7.18043566,   7.67956638],\n",
       "       [ -7.35469866,   7.74246359],\n",
       "       [ -6.30501366,   6.47881651],\n",
       "       [ -6.66385221,   7.3100071 ],\n",
       "       [ -6.36667585,   8.19366646],\n",
       "       [ -8.25523376,   8.77671528],\n",
       "       [ -7.14616346,   7.43907118],\n",
       "       [ -7.79763842,   9.39667892],\n",
       "       [ -7.10636425,   8.5675602 ],\n",
       "       [ -6.65632153,   6.82556581],\n",
       "       [ -7.36716557,   6.98777819],\n",
       "       [ -7.72445154,   8.5553894 ],\n",
       "       [ -7.00737047,   7.31062555],\n",
       "       [ -8.98712826,   9.90948677],\n",
       "       [ -8.0236578 ,   7.07927704],\n",
       "       [ -6.91179991,   7.88581228],\n",
       "       [ -7.21345282,   8.0273962 ],\n",
       "       [ -5.82658529,   7.20275545],\n",
       "       [ -7.23927355,   9.04325581],\n",
       "       [ -7.48513937,   8.24025154],\n",
       "       [ -7.55669022,   7.64070177],\n",
       "       [ -5.69212818,   7.8215127 ],\n",
       "       [ -6.5070982 ,   7.86971188],\n",
       "       [ -6.82218361,   8.71184921],\n",
       "       [ -8.18555737,  11.21798611],\n",
       "       [ -8.069067  ,   7.9307847 ],\n",
       "       [ -6.47659779,   7.02936888],\n",
       "       [ -8.08265972,   9.00176907],\n",
       "       [ -5.97798204,   7.80774307],\n",
       "       [ -7.91077805,   7.94543219],\n",
       "       [ -7.5535512 ,   9.03356743],\n",
       "       [ -4.70536089,   6.40868425],\n",
       "       [ -7.34841013,   7.30880499],\n",
       "       [ -5.4499383 ,   6.30605984],\n",
       "       [ -7.01755857,   6.9674201 ],\n",
       "       [ -7.07211351,   9.44935226],\n",
       "       [ -6.36980104,   7.61466932],\n",
       "       [ -5.8172636 ,   6.86873198],\n",
       "       [ -7.01079893,   6.98739004],\n",
       "       [ -7.46841288,   7.44196606],\n",
       "       [ -5.65271521,   8.29687786],\n",
       "       [ -6.0530901 ,   7.06062746],\n",
       "       [ -7.31460476,   7.0422473 ],\n",
       "       [ -6.90229607,   8.4064045 ],\n",
       "       [ -6.95500231,   8.02627087],\n",
       "       [ -7.6630826 ,   7.17363024],\n",
       "       [ -4.02015877,   7.44918203],\n",
       "       [ -8.50396538,   9.14995766],\n",
       "       [ -6.6704154 ,   6.79537916],\n",
       "       [ -6.55449915,   7.22864914],\n",
       "       [ -7.80732155,   8.7022562 ],\n",
       "       [ -6.88440228,   8.62864113],\n",
       "       [ -6.81325293,   7.10802555],\n",
       "       [ -7.39593601,   7.96284533],\n",
       "       [ -5.50783968,   5.9838953 ],\n",
       "       [ -7.06627178,   8.58469296],\n",
       "       [ -7.11398506,   8.90825748],\n",
       "       [ -6.67969847,   7.83074856],\n",
       "       [ -6.77680635,   8.10391998],\n",
       "       [ -7.0031867 ,   6.58494854],\n",
       "       [ -5.87458181,   8.93283749],\n",
       "       [ -6.23130369,   8.07783508],\n",
       "       [ -9.5229187 ,  11.27761173],\n",
       "       [ -7.34214354,   7.97075987],\n",
       "       [ -7.34075689,   9.40286064],\n",
       "       [ -6.78809023,   8.13382721],\n",
       "       [ -6.22848558,   7.55550385],\n",
       "       [ -6.19861698,   8.24160385],\n",
       "       [ -6.80112696,   8.67708588],\n",
       "       [ -7.3394227 ,   7.42209864],\n",
       "       [ -6.47584248,   7.5900321 ]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing values\n",
    "y_ = tf.matmul(h_drop, W_fc3) + b_fc3\n",
    "predicted = y_.eval(feed_dict={x: X_test, pkeep: 0.8})\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
